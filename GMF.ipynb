{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import initializations\n",
    "from keras.models import Sequential, Model, load_model, save_model\n",
    "from keras.layers.core import Dense, Lambda, Activation\n",
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Merge, Flatten\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (94, 4219)\t1.0\n",
      "  (17, 979)\t1.0\n",
      "  (331, 13828)\t1.0\n",
      "  (104, 5479)\t1.0\n",
      "  (481, 20172)\t1.0\n",
      "  (792, 28958)\t1.0\n",
      "  (965, 3542)\t1.0\n",
      "  (26, 931)\t1.0\n",
      "  (105, 5577)\t1.0\n",
      "  (134, 350)\t1.0\n",
      "  (483, 20281)\t1.0\n",
      "  (946, 28275)\t1.0\n",
      "  (130, 6777)\t1.0\n",
      "  (262, 12086)\t1.0\n",
      "  (955, 2063)\t1.0\n",
      "  (454, 10010)\t1.0\n",
      "  (456, 18970)\t1.0\n",
      "  (272, 5569)\t1.0\n",
      "  (751, 1046)\t1.0\n",
      "  (294, 7527)\t1.0\n",
      "  (381, 14077)\t1.0\n",
      "  (452, 1064)\t1.0\n",
      "  (968, 18113)\t1.0\n",
      "  (380, 311)\t1.0\n",
      "  (182, 8986)\t1.0\n",
      "  :\t:\n",
      "  (377, 15936)\t1.0\n",
      "  (553, 22172)\t1.0\n",
      "  (72, 3868)\t1.0\n",
      "  (932, 13269)\t1.0\n",
      "  (27, 1311)\t1.0\n",
      "  (768, 9736)\t1.0\n",
      "  (242, 2348)\t1.0\n",
      "  (456, 17401)\t1.0\n",
      "  (97, 5010)\t1.0\n",
      "  (573, 18191)\t1.0\n",
      "  (895, 1051)\t1.0\n",
      "  (689, 7178)\t1.0\n",
      "  (439, 6507)\t1.0\n",
      "  (262, 1)\t1.0\n",
      "  (470, 19770)\t1.0\n",
      "  (548, 2830)\t1.0\n",
      "  (448, 18705)\t1.0\n",
      "  (83, 4172)\t1.0\n",
      "  (453, 17920)\t1.0\n",
      "  (570, 2410)\t1.0\n",
      "  (955, 33256)\t1.0\n",
      "  (357, 15324)\t1.0\n",
      "  (794, 934)\t1.0\n",
      "  (651, 1011)\t1.0\n",
      "  (68, 3499)\t1.0\n",
      "1001 34444\n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Arguments ####################\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Run GMF.\")\n",
    "    parser.add_argument('--path', nargs='?', default='',\n",
    "                        help='Input data path.')\n",
    "    parser.add_argument('--dataset', nargs='?', default='mpd.slice.0-999.json',\n",
    "                        help='Choose a dataset.')\n",
    "    parser.add_argument('--epochs', type=int, default=10,\n",
    "                        help='Number of epochs.')\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='Batch size.')\n",
    "    parser.add_argument('--num_factors', type=int, default=8,\n",
    "                        help='Embedding size.')\n",
    "    parser.add_argument('--regs', nargs='?', default='[0,0]',\n",
    "                        help=\"Regularization for user and item embeddings.\")\n",
    "    parser.add_argument('--num_neg', type=int, default=4,\n",
    "                        help='Number of negative instances to pair with a positive instance.')\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                        help='Learning rate.')\n",
    "    parser.add_argument('--learner', nargs='?', default='adam',\n",
    "                        help='Specify an optimizer: adagrad, adam, rmsprop, sgd')\n",
    "    parser.add_argument('--verbose', type=int, default=1,\n",
    "                        help='Show performance per X iterations')\n",
    "    parser.add_argument('--out', type=int, default=1,\n",
    "                        help='Whether to save the trained model.')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the negative cases by generating a random number (until we get one for which there is not entry in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instances(train, pMat, num_negatives):\n",
    "    user_input, item_input, labels = [],[],[]\n",
    "    num_users = train.shape[0]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for t in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while (u, j) in pMat.keys():\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(shape, name=None):\n",
    "    return initializations.normal(shape, scale=0.01, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, latent_dim, regs=[0,0]):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding',\n",
    "                                  init = init_normal, W_regularizer = l2(regs[0]), input_length=1)\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding',\n",
    "                                  init = init_normal, W_regularizer = l2(regs[1]), input_length=1)   \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
    "    \n",
    "    # Element-wise product of user and item embeddings \n",
    "    predict_vector = merge([user_latent, item_latent], mode = 'mul')\n",
    "    \n",
    "    # Final prediction layer\n",
    "    #prediction = Lambda(lambda x: K.sigmoid(K.sum(x)), output_shape=(1,))(predict_vector)\n",
    "    prediction = Dense(1, activation='sigmoid', init='lecun_uniform', name = 'prediction')(predict_vector)\n",
    "    \n",
    "    model = Model(input=[user_input, item_input], \n",
    "                output=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--path [PATH]] [--dataset [DATASET]]\n",
      "                             [--epochs EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                             [--num_factors NUM_FACTORS] [--regs [REGS]]\n",
      "                             [--num_neg NUM_NEG] [--lr LR]\n",
      "                             [--learner [LEARNER]] [--verbose VERBOSE]\n",
      "                             [--out OUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-aa2a4af1-ce19-4320-aa1d-d952b609b13c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    num_factors = args.num_factors\n",
    "    regs = eval(args.regs)\n",
    "    num_negatives = args.num_neg\n",
    "    learner = args.learner\n",
    "    learning_rate = args.lr\n",
    "    epochs = args.epochs\n",
    "    batch_size = args.batch_size\n",
    "    verbose = args.verbose\n",
    "    \n",
    "    print(\"GMF arguments: %s\" %(args))\n",
    "    model_out_file = 'Pretrain/%s_GMF_%d_%d.h5' %(args.dataset, num_factors, time())\n",
    "    \n",
    "    # Loading data\n",
    "    dataset = Dataset(args.path + args.dataset)\n",
    "    train = dataset.trainMatrix\n",
    "    pMat = dataset.playlistMatrix \n",
    "    num_users, num_items = train.shape\n",
    "    print(\"Loaded data\")\n",
    "    \n",
    "    # Build model\n",
    "    model = get_model(num_users, num_items, num_factors, regs)\n",
    "    if learner.lower() == \"adagrad\": \n",
    "        model.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy')\n",
    "    elif learner.lower() == \"rmsprop\":\n",
    "        model.compile(optimizer=RMSprop(lr=learning_rate), loss='binary_crossentropy')\n",
    "    elif learner.lower() == \"adam\":\n",
    "        model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
    "    else:\n",
    "        model.compile(optimizer=SGD(lr=learning_rate), loss='binary_crossentropy')\n",
    "    print(model.summary())\n",
    "    \n",
    "    \n",
    "    # Train model\n",
    "    best_iter =  -1\n",
    "    for epoch in range(epochs):\n",
    "        t1 = time()\n",
    "        # Generate training instances\n",
    "        user_input, item_input, labels = get_train_instances(train, pMat, num_negatives)\n",
    "        \n",
    "        # Training\n",
    "        hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                         np.array(labels), # labels \n",
    "                         batch_size=batch_size, nb_epoch=1, verbose=0, shuffle=True)\n",
    "        t2 = time()\n",
    "        \n",
    "        # Evaluation\n",
    "        if epoch %verbose == 0:\n",
    "            loss = hist.history['loss'][0]\n",
    "            print('Iteration %d [%.1f s]: loss = %.4f [%.1f s]' \n",
    "                  % (epoch,  t2-t1, loss, time()-t2))\n",
    "            if args.out > 0:\n",
    "                model.save_weights(model_out_file, overwrite=True)\n",
    "\n",
    "    if args.out > 0:\n",
    "        print(\"The GMF model is saved to %s\" %(model_out_file))\n",
    "    u = 262\n",
    "    items = [1064 ,174 ,2791 ,3373 ,269 ,2678 ,1902 ,3641 ,1216 ,915 ,3672 ,2803 ,2344 ,986 ,3217 ,2824 ,2598 ,464 ,2340]\n",
    "    items.append(12086)\n",
    "    user = np.full(len(items), u, dtype = 'int32')\n",
    "    \n",
    "    predictions = model.predict([user, np.array(items)])\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3 GMF.py --dataset ml-1m --epochs 20 --batch_size 256 --num_factors 8 --regs [0,0] --num_neg 4 --lr 0.001 --learner adam --verbose 1 --out 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using Theano backend.\n",
      "1.0\n",
      "66721\n",
      "1001 34444\n",
      "GMF arguments: Namespace(batch_size=64, dataset='mpd.slice.0-999.json', epochs=10, learner='adam', lr=0.001, num_factors=8, num_neg=4, out=1, path='', regs='[0,0]', verbose=1)\n",
      "Loaded data\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "item_input (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "user_embedding (Embedding)       (None, 1, 8)          8008        user_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "item_embedding (Embedding)       (None, 1, 8)          275552      item_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 8)             0           user_embedding[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 8)             0           item_embedding[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 8)             0           flatten_1[0][0]                  \n",
      "                                                                   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "prediction (Dense)               (None, 1)             9           merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 283,569\n",
      "Trainable params: 283,569\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Iteration 0 [39.1 s]: loss = 0.5140 [0.0 s]\n",
      "/home/avi/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Iteration 1 [41.7 s]: loss = 0.4199 [0.0 s]\n",
      "Iteration 2 [41.9 s]: loss = 0.3592 [0.0 s]\n",
      "Iteration 3 [41.5 s]: loss = 0.3101 [0.0 s]\n",
      "Iteration 4 [41.6 s]: loss = 0.2700 [0.0 s]\n",
      "Iteration 5 [42.0 s]: loss = 0.2418 [0.0 s]\n",
      "Iteration 6 [41.8 s]: loss = 0.2198 [0.0 s]\n",
      "Iteration 7 [42.0 s]: loss = 0.2016 [0.0 s]\n",
      "Iteration 8 [42.1 s]: loss = 0.1872 [0.0 s]\n",
      "Iteration 9 [42.3 s]: loss = 0.1747 [0.0 s]\n",
      "The GMF model is saved to Pretrain/mpd.slice.0-999.json_GMF_8_1517659410.h5\n",
      "[[9.7569454e-01]\n",
      " [2.4721504e-03]\n",
      " [3.7099369e-02]\n",
      " [1.0026862e-02]\n",
      " [1.7816721e-03]\n",
      " [6.7988023e-02]\n",
      " [2.4303155e-01]\n",
      " [1.1860360e-03]\n",
      " [3.3592849e-04]\n",
      " [4.9465466e-06]\n",
      " [8.2312655e-03]\n",
      " [2.8610671e-01]\n",
      " [9.5864522e-01]\n",
      " [6.6481960e-01]\n",
      " [3.5493274e-04]\n",
      " [8.2542449e-03]\n",
      " [2.8098643e-06]\n",
      " [2.3859061e-04]\n",
      " [1.9851709e-02]]\n",
      "Traceback (most recent call last):\n",
      "  File \"GMF.py\", line 200, in <module>\n",
      "    get_ipython().system(' python3 GMF.py')\n",
      "NameError: name 'get_ipython' is not defined\n"
     ]
    }
   ],
   "source": [
    "! python3 GMF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sp.dok_matrix((1, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mat.has_key(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting for one playlist\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
